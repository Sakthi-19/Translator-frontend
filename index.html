<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            /* Fallback for browsers that don't support gradients */
            background-color: #4e4376;
            /* Old browsers */
            background-image: linear-gradient(to right, #2b5876, #4e4376);
            /* Standard syntax */

            /* Ensure text is readable on the gradient */
            color: #ffffff;
            /* White text */
        }

        select {
            border: 1px solid #007bff;
            border-radius: 5px;
        }

        #msg {
            visibility: hidden;
            color: red;
            font-weight: bold;
            font-size: 22px;
            font-family: Verdana;
        }

        button {
            padding: 5px 10px;
            border: 1px solid grey;
            font-size: 18px;
            background: white;
        }

        .audio-controls {
            display: flex;
            align-items: center;
            padding-top: 20px;
            justify-content: center;
        }

        .audio-controls button {
            margin: 0px 5px;
        }

        canvas {
            margin-top: 10px;
            background-color: black;
        }

        select {
            height: 25px;
            margin: 0px 5px;
        }

        a {
            margin-left: 20px;
        }

        .app {
            text-align: center;
            padding-top: 20px;
        }
    </style>


    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

</head>

<body>

    <div class="container">
        <div class="row">
            <div class="col-md-2"></div>
            <div class="col-md-8">

                <div class="app">
                    <select name="" class="form-select" id="micSelect"></select>

                    <select id="visSelect">
                        <option value="frequencybars">Bar</option>
                        <option value="sinewave">Wave</option>
                        <option value="circle">Circle</option>
                    </select>

                    <!-- <a id="download">Download</a> -->

                    <div class="audio-controls">
                        <button id="record" class="btn btn-primary">Record</button>
                        <button id="stop" class="btn btn-primary">Stop</button>
                        <audio id="audio" controls></audio>
                    </div>

                    <div id="msg">Recording...</div>
                    <canvas width="500" height="200"></canvas>


                </div>

            </div>
            <div class="col-md-2"></div>
        </div>

        <div class="row" style="margin-top: 25px;">
            <div class="col-md-2"></div>
            <div class="col-md-8" style="text-align: center;">
                <button id="downloadOutput" class="btn btn-primary">Download Output</button>
            </div>
            <div class="col-md-2"></div>
        </div>


    </div>





    <script>
        var currentText = "";
        var recognition = new webkitSpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {
            let finalTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                }
            }

            if (finalTranscript.trim().length) { fetchData(finalTranscript) }


            console.log(finalTranscript);
        };

        document.getElementById("downloadOutput").addEventListener("click", () => {
            downloadOutput('https://node-js-nw38.onrender.com/hear?text=' + currentText)


        });

        function downloadOutput(url) {

            $.ajax({
                url: url,
                method: "GET",
                xhrFields: {
                    responseType: "blob" // Set response type to blob
                },
                success: function (blobData) {
                    // Create a blob from the response
                    var blob = new Blob([blobData], { type: "audio/mpeg" });
                    var audio = new Audio();
                    var blobUrl = URL.createObjectURL(blob);
                    audio.src = blobUrl;
                    audio.play();

                    // Create a download link
                    var url = window.URL.createObjectURL(blob);
                    var a = document.createElement("a");
                    a.href = url;
                    a.download = "filename.mp3"; // Specify the filename
                    document.body.appendChild(a);
                    // Initiate the download
                    a.click();

                    // Clean up
                    window.URL.revokeObjectURL(url);
                    document.body.removeChild(a);
                },
                error: function (xhr, status, error) {
                    console.error("Error downloading file:", error);
                }
            });

        }

        function speakTextWithAPI() {

        }



        function speakText(text, index) {
            const utterance = new SpeechSynthesisUtterance();
            utterance.text = text;
            utterance.pitch = 1.5;// Set rate (0.1 to 10, 1 is default)
            utterance.rate = 1; // slow
            utterance.lang = 'ta-IN';
            utterance.voice = window.speechSynthesis.getVoices()[index];
        }

        function fetchData(text) {
            $.ajax({
                url: "https://node-js-nw38.onrender.com/translate?text=" + text, // Example URL
                method: "GET",
                success: function (data) {
                    // On success, update the data container
                    speakText(data.TRANSLATED)
                    currentText = data.TRANSLATED
                    downloadOutput('https://node-js-nw38.onrender.com/hear?text=' + currentText)

                },
                error: function (xhr, status, error) {
                    // On error, log the error to console
                    console.error("Error:", error);
                }
            });
        }





        (async () => {
            let leftchannel = [];
            let rightchannel = [];
            let recorder = null;
            let recording = false;
            let recordingLength = 0;
            let volume = null;
            let audioInput = null;
            let sampleRate = null;
            let AudioContext = window.AudioContext || window.webkitAudioContext;
            let context = null;
            let analyser = null;
            let canvas = document.querySelector('canvas');
            let canvasCtx = canvas.getContext("2d");
            let visualSelect = document.querySelector('#visSelect');
            let micSelect = document.querySelector('#micSelect');
            let stream = null;
            let tested = false;

            try {
                window.stream = stream = await getStream();
            } catch (err) {
                alert('Issue getting mic', err);
            }

            const deviceInfos = await navigator.mediaDevices.enumerateDevices();

            var mics = [];
            for (let i = 0; i !== deviceInfos.length; ++i) {
                let deviceInfo = deviceInfos[i];
                if (deviceInfo.kind === 'audioinput') {
                    mics.push(deviceInfo);
                    let label = deviceInfo.label ||
                        'Microphone ' + mics.length;
                    console.log('Mic ', label + ' ' + deviceInfo.deviceId)
                    const option = document.createElement('option')
                    option.value = deviceInfo.deviceId;
                    option.text = label;
                    micSelect.appendChild(option);
                }
            }

            function getStream(constraints) {
                if (!constraints) {
                    constraints = { audio: true, video: false };
                }
                return navigator.mediaDevices.getUserMedia(constraints);
            }


            // setUpRecording();

            function setUpRecording() {
                context = new AudioContext();
                sampleRate = context.sampleRate;

                // creates a gain node
                volume = context.createGain();

                // creates an audio node from teh microphone incoming stream
                audioInput = context.createMediaStreamSource(stream);

                // Create analyser
                analyser = context.createAnalyser();

                // connect audio input to the analyser
                audioInput.connect(analyser);

                // connect analyser to the volume control
                // analyser.connect(volume);

                let bufferSize = 2048;
                let recorder = context.createScriptProcessor(bufferSize, 2, 2);

                // we connect the volume control to the processor
                // volume.connect(recorder);

                analyser.connect(recorder);

                // finally connect the processor to the output
                recorder.connect(context.destination);

                recorder.onaudioprocess = function (e) {
                    // Check 
                    if (!recording) return;
                    // Do something with the data, i.e Convert this to WAV
                    let left = e.inputBuffer.getChannelData(0);
                    let right = e.inputBuffer.getChannelData(1);
                    if (!tested) {
                        tested = true;
                        // if this reduces to 0 we are not getting any sound
                        if (!left.reduce((a, b) => a + b)) {
                            alert("There seems to be an issue with your Mic");
                            // clean up;
                            stop();
                            stream.getTracks().forEach(function (track) {
                                track.stop();
                            });
                            context.close();
                        }
                    }
                    // we clone the samples
                    leftchannel.push(new Float32Array(left));
                    rightchannel.push(new Float32Array(right));
                    recordingLength += bufferSize;
                };
                visualize();
            };



            function mergeBuffers(channelBuffer, recordingLength) {
                let result = new Float32Array(recordingLength);
                let offset = 0;
                let lng = channelBuffer.length;
                for (let i = 0; i < lng; i++) {
                    let buffer = channelBuffer[i];
                    result.set(buffer, offset);
                    offset += buffer.length;
                }
                return result;
            }

            function interleave(leftChannel, rightChannel) {
                let length = leftChannel.length + rightChannel.length;
                let result = new Float32Array(length);

                let inputIndex = 0;

                for (let index = 0; index < length;) {
                    result[index++] = leftChannel[inputIndex];
                    result[index++] = rightChannel[inputIndex];
                    inputIndex++;
                }
                return result;
            }

            function writeUTFBytes(view, offset, string) {
                let lng = string.length;
                for (let i = 0; i < lng; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            function start() {

                recognition.start();
                recording = true;
                document.querySelector('#msg').style.visibility = 'visible'
                // reset the buffers for the new recording
                leftchannel.length = rightchannel.length = 0;
                recordingLength = 0;
                console.log('context: ', !!context);
                if (!context) setUpRecording();
            }

            function stop() {
                recognition.stop()
                recording = false;
                document.querySelector('#msg').style.visibility = 'hidden'


                // we flat the left and right channels down
                let leftBuffer = mergeBuffers(leftchannel, recordingLength);
                let rightBuffer = mergeBuffers(rightchannel, recordingLength);
                // we interleave both channels together
                let interleaved = interleave(leftBuffer, rightBuffer);

                ///////////// WAV Encode /////////////////
                // from http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/
                //

                // we create our wav file
                let buffer = new ArrayBuffer(44 + interleaved.length * 2);
                let view = new DataView(buffer);

                // RIFF chunk descriptor
                writeUTFBytes(view, 0, 'RIFF');
                view.setUint32(4, 44 + interleaved.length * 2, true);
                writeUTFBytes(view, 8, 'WAVE');
                // FMT sub-chunk
                writeUTFBytes(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                // stereo (2 channels)
                view.setUint16(22, 2, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * 4, true);
                view.setUint16(32, 4, true);
                view.setUint16(34, 16, true);
                // data sub-chunk
                writeUTFBytes(view, 36, 'data');
                view.setUint32(40, interleaved.length * 2, true);

                // write the PCM samples
                let lng = interleaved.length;
                let index = 44;
                let volume = 1;
                for (let i = 0; i < lng; i++) {
                    view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
                    index += 2;
                }

                // our final binary blob
                const blob = new Blob([view], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(blob);
                document.querySelector('#audio').setAttribute('src', audioUrl);

            }

            function visualize() {
                WIDTH = canvas.width;
                HEIGHT = canvas.height;
                CENTERX = canvas.width / 2;
                CENTERY = canvas.height / 2;

                let visualSetting = visualSelect.value;
                if (!analyser) return;

                if (visualSetting === "sinewave") {
                    analyser.fftSize = 2048;
                    var bufferLength = analyser.fftSize;
                    var dataArray = new Uint8Array(bufferLength);
                    canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
                    var draw = function () {

                        drawVisual = requestAnimationFrame(draw);

                        analyser.getByteTimeDomainData(dataArray);

                        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
                        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                        canvasCtx.lineWidth = 2;
                        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

                        canvasCtx.beginPath();

                        var sliceWidth = WIDTH * 1.0 / bufferLength;
                        var x = 0;

                        for (var i = 0; i < bufferLength; i++) {

                            var v = dataArray[i] / 128.0;
                            var y = v * HEIGHT / 2;

                            if (i === 0) {
                                canvasCtx.moveTo(x, y);
                            } else {
                                canvasCtx.lineTo(x, y);
                            }

                            x += sliceWidth;
                        }

                        canvasCtx.lineTo(canvas.width, canvas.height / 2);
                        canvasCtx.stroke();
                    };

                    draw();

                } else if (visualSetting == "frequencybars") {
                    analyser.fftSize = 64;
                    var bufferLengthAlt = analyser.frequencyBinCount;
                    var dataArrayAlt = new Uint8Array(bufferLengthAlt);
                    canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

                    var drawAlt = function () {
                        drawVisual = requestAnimationFrame(drawAlt);

                        analyser.getByteFrequencyData(dataArrayAlt);

                        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
                        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                        var barWidth = (WIDTH / bufferLengthAlt);
                        var barHeight;
                        var x = 0;

                        for (var i = 0; i < bufferLengthAlt; i++) {
                            barHeight = dataArrayAlt[i];

                            canvasCtx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
                            canvasCtx.fillRect(x, HEIGHT - barHeight / 2, barWidth, barHeight / 2);

                            x += barWidth + 1;
                        }
                    };

                    drawAlt();

                } else if (visualSetting == "circle") {
                    analyser.fftSize = 32;
                    let bufferLength = analyser.frequencyBinCount;
                    console.log(bufferLength);
                    let dataArray = new Uint8Array(bufferLength);

                    canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

                    let draw = () => {
                        drawVisual = requestAnimationFrame(draw);

                        analyser.getByteFrequencyData(dataArray);
                        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
                        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

                        // let radius = dataArray.reduce((a,b) => a + b) / bufferLength;
                        let radius = dataArray[2] / 2
                        if (radius < 20) radius = 20;
                        if (radius > 100) radius = 100;
                        canvasCtx.beginPath();
                        canvasCtx.arc(CENTERX, CENTERY, radius, 0, 2 * Math.PI, false);
                        // canvasCtx.fillStyle = 'rgb(50,50,' + (radius+100) +')';
                        // canvasCtx.fill();
                        canvasCtx.lineWidth = 6;
                        canvasCtx.strokeStyle = 'rgb(50,50,' + (radius + 100) + ')';
                        canvasCtx.stroke();
                    }
                    draw()
                }

            }

            visualSelect.onchange = function () {
                window.cancelAnimationFrame(drawVisual);
                visualize();
            };

            micSelect.onchange = async e => {
                stream.getTracks().forEach(function (track) {
                    track.stop();
                });
                context.close();

                stream = await getStream({
                    audio: {
                        deviceId: { exact: micSelect.value }
                    }, video: false
                });
                setUpRecording();
            }

            function pause() {
                recording = false;
                context.suspend()
            }

            function resume() {
                recording = true;
                context.resume();
            }

            document.querySelector('#record').onclick = (e) => {
                start();
            }

            document.querySelector('#stop').onclick = (e) => {
                stop();
            }
        })()
    </script>

</body>

</html>